{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fde7800-3d49-40fb-9ed5-52823299bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e181de7b-5ac9-4bb6-bae3-373d2438f45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j-i12b106/.conda/envs/diffusion/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from diffusers import StableDiffusionXLPipeline, DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from transformers import CLIPTokenizer\n",
    "from gen_prompt import gen_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da62c1bb-afe6-4bc9-a82e-813ecf4d6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    " style_lora_models = {\n",
    "    \"watercolor\": \"ostris/watercolor_style_lora_sdxl\",\n",
    "    \"embroidery\": \"ostris/embroidery_style_lora_sdxl\",\n",
    "    \"pixel_art\": \"artificialguybr/PixelArtRedmond\",\n",
    "    \"linear_manga\": \"artificialguybr/LineAniRedmond-LinearMangaSDXL-V2\",\n",
    "    \"studio_ghibli\": \"artificialguybr/StudioGhibli.Redmond-V2\",\n",
    "    \"3d_style\": \"artificialguybr/3DRedmond-V1\",\n",
    "    \"tshirt_design\": \"artificialguybr/TshirtDesignRedmond-V2\",\n",
    "    \"storybook\": \"artificialguybr/StoryBookRedmond-V2\",\n",
    "    \"cute_cartoon\": \"artificialguybr/CuteCartoonRedmond-V2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ccaf95-90b3-424a-a302-f3c498967a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = \"./result_img\"\n",
    "\n",
    "loaded_adapters = set()\n",
    "\n",
    "def gen_image(pipe, style, prompt, negative_prompt='', save=False):\n",
    "    lora_model_id = style_lora_models[style]\n",
    "    model_name = lora_model_id.split('/')[-1]\n",
    "    if style in loaded_adapters:\n",
    "        print(f\"⚠️ Adapter '{style}' is already loaded. Skipping duplicate load.\")\n",
    "    else:\n",
    "        pipe.load_lora_weights(lora_model_id, adapter_name=style)\n",
    "        loaded_adapters.add(style)\n",
    "        print(f\"✅ Loaded Adapter: {style}\")\n",
    "        # LoRA 모델 적용 (PEFT 백엔드 사용)\n",
    "    \n",
    "    image = pipe(\n",
    "        prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_inference_steps=30,\n",
    "    ).images[0]\n",
    "    \n",
    "    # 이미지 저장 및 출력\n",
    "    if save:\n",
    "        image.save(os.path.join(IMG_PATH, f\"{style}-{model_name}\") + '.png')\n",
    "    return image\n",
    "\n",
    "def gen_image_pipline(genre, style, title, worldview, synopsis, characters, keywords):\n",
    "    print(\"Generate Prompt...\")\n",
    "    prompt, negative_prompt = gen_prompt(genre, style, title, worldview, synopsis, characters, keywords)\n",
    "    print(\"Generate Image...\")\n",
    "    image = gen_image(pipe, style, prompt, negative_prompt, save=True)\n",
    "\n",
    "    image.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0162792-d390-45f5-8140-ca55c4c80590",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = '일상'\n",
    "title = '여름 도둑'\n",
    "worldview = '2025년 한국의 학교'\n",
    "synopsis = '학교를 다니는 일상'\n",
    "characters = 'a man'\n",
    "keywords = '아련한, 즐거운, 행복한'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd298f5-7770-4fae-a748-9b71a9bb2dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:07<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# base_model_id = \"cagliostrolab/animagine-xl-4.0\"\n",
    "# base_model_id = \"digiplay/AnalogMadness-realistic-model-v7\"\n",
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "# pipe = StableDiffusionXLPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16)\n",
    "pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16)\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# PEFT 백엔드 활성화\n",
    "pipe.enable_xformers_memory_efficient_attention()  # 메모리 최적화\n",
    "pipe.enable_model_cpu_offload()  # CPU 오프로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92756350-2927-487c-89a2-485a8a80c846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate image use watercolor...\n",
      "Generate Prompt...\n",
      "Generate Image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (79 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['palette )']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded Adapter: watercolor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (79 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['palette )']\n",
      " 97%|█████████▋| 29/30 [00:36<00:00,  1.23it/s]"
     ]
    }
   ],
   "source": [
    "# test all models\n",
    "for style in style_lora_models:\n",
    "    print(f\"Generate image use {style}...\")\n",
    "    gen_image_pipline(genre, style, title, worldview, synopsis, characters, keywords)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e4cef-c3e7-4493-8ab9-905f70852cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
